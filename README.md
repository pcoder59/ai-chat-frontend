# AI Chat Frontend

A Simple Frontend for Ollama written in python

# Requirement

- Ollama should be hosted on the system: refer [text](https://github.com/ollama/ollama)
- Ollama python module: refer [text](https://github.com/ollama/ollama-python)

# Usage

- Run main.py and enter the model you want to use. By default it uses llama2-uncensored if not enetered
- Type the prompt and wait for the response
- If Model does not exist, it will try to pull the model with ollama